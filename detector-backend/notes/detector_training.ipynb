{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oGMrcv_VX-Kx",
    "ExecuteTime": {
     "end_time": "2025-11-08T09:32:04.847999Z",
     "start_time": "2025-11-08T09:32:04.846357Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    ")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from transformers import (\n",
    "    DistilBertTokenizer,\n",
    "    DistilBertForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from pymongo import MongoClient"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "source": [
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gYQFfwsWkyMa",
    "outputId": "8f4e7f74-2301-4e34-874e-cee08a1309f6",
    "ExecuteTime": {
     "end_time": "2025-11-08T09:32:04.856651Z",
     "start_time": "2025-11-08T09:32:04.854511Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Preprocessing"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "coll = client.get_database(\"fakenews\").get_collection(\"articles\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Get English or German Articles\n",
    "language = \"en\"\n",
    "df = pd.DataFrame(list(coll.find({\"language\": language})))"
   ],
   "metadata": {
    "id": "lzLfpsrOi2JW",
    "ExecuteTime": {
     "end_time": "2025-11-08T09:32:06.039029Z",
     "start_time": "2025-11-08T09:32:04.863836Z"
    }
   },
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Remap label to numeric for training\n",
    "df[\"label\"] = df[\"label\"].map({\"fake\": 0, \"real\": 1})\n",
    "# Combine Title and Text\n",
    "df[\"content\"] = df[\"title\"] + \" [SEP] \" + df[\"text\"]\n",
    "# Remove duplicates and missing values\n",
    "df = df.copy().dropna(subset=[\"content\", \"label\"]).drop_duplicates(subset=[\"content\"])\n",
    "# Clean formatting errors\n",
    "df[\"content\"] = (\n",
    "    df[\"content\"]\n",
    "    .str.replace(\"Ã¤\", \"ä\", regex=True)\n",
    "    .replace(\"Ã¼\", \"ü\", regex=True)\n",
    "    .replace(\"Ã¶\", \"ö\", regex=True)\n",
    "    .replace(\"kã\", \"kä\", regex=True)\n",
    "    .replace(\"fã¼r\", \"für\", regex=True)\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Balance dataset by undersampling\n",
    "df[\"label\"] = df[\"label\"].astype(int)\n",
    "df = df.groupby(\"label\").sample(df.groupby(\"label\").size().min())"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Baseline Model to identify the most important words\n",
    "The primary objective for using this baseline model is to try and prevent overfitting.\n",
    "By identifying and removing specific words or meta topics, which the model might use to shortcut the learning process, it prevents the model from focussing on the specific format of this dataset and rather focus on the nature of misinformation."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "vectorizer = CountVectorizer(max_features=10000)\n",
    "X = vectorizer.fit_transform(df[\"content\"])\n",
    "y = df[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Baseline Accuracy: {clf.score(X_test, y_test):.4f}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Calucalate coefficients\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "coefs = clf.coef_[0]\n",
    "\n",
    "# Sort and print Top 20 words for each label\n",
    "top_positive = np.argsort(coefs)[-20:]\n",
    "top_negative = np.argsort(coefs)[:20]\n",
    "\n",
    "print(\"Real\")\n",
    "print([feature_names[j] for j in top_positive])\n",
    "\n",
    "print(\"\\nFake\")\n",
    "print([feature_names[j] for j in top_negative])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training the model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Prepare Training and validation Datasets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df[\"content\"].tolist(),\n",
    "    df[\"label\"].tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=141,\n",
    "    stratify=df[\"label\"],\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if language == \"en\":\n",
    "    bert_identifier = \"distilbert-base-cased\"\n",
    "elif language == \"de\":\n",
    "    bert_identifier = \"distlibert-base-german-cased\"\n",
    "else:\n",
    "    bert_identifier = \"distilbert-base-multilingual-cased \"\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(bert_identifier)\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    bert_identifier, num_labels=2\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Use the maximum length possible for news articles\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Setup dataset\n",
    "class FakeNewsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_dataset = FakeNewsDataset(train_encodings, train_labels)\n",
    "val_dataset = FakeNewsDataset(val_encodings, val_labels)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define metrics for validation while training\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=predictions)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true=labels, y_pred=predictions, average=\"weighted\"\n",
    "    )\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"f1\": f1, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Paramaters might need tuning for the language and size of the dataset used\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    save_strategy=\"no\",\n",
    "    learning_rate=2e-5,\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "trainer.train()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## English Validation Results (Epoch 2/2)\n",
    "```\n",
    "Step\tTraining Loss\tValidation Loss\tAccuracy\tF1\tPrecision\tRecall\n",
    "1000\t0.068600\t0.081274\t0.978367\t0.978366\t0.978516\t0.978367\n",
    "2000\t0.056800\t0.045051\t0.989317\t0.989317\t0.989340\t0.989317\n",
    "3000\t0.025000\t0.033110\t0.992789\t0.992789\t0.992793\t0.992789\n",
    "4000\t0.031600\t0.028730\t0.994213\t0.994213\t0.994229\t0.994213\n",
    "5000\t0.025100\t0.022759\t0.993857\t0.993857\t0.993858\t0.993857\n",
    "```"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## German Validation Results (Epoch 2/2)\n",
    "```\n",
    "Step\tTraining Loss\tVal Loss\tAccuracy\tF1\tPrecision\tRecall\n",
    "1000\t0.124400\t0.122266\t0.955190\t0.955167\t0.956129\t0.955190\n",
    "2000\t0.105400\t0.081241\t0.970214\t0.970213\t0.970249\t0.970214\n",
    "3000\t0.063900\t0.067688\t0.976405\t0.976403\t0.976559\t0.976405\n",
    "4000\t0.069200\t0.059439\t0.979547\t0.979547\t0.979578\t0.979547\n",
    "5000\t0.072900\t0.053993\t0.980440\t0.980439\t0.980529\t0.980440\n",
    "6000\t0.034500\t0.052662\t0.983192\t0.983192\t0.983199\t0.983192\n",
    "7000\t0.035000\t0.047028\t0.986074\t0.986073\t0.986098\t0.986074\n",
    "8000\t0.022300\t0.049871\t0.986036\t0.986036\t0.986043\t0.986036\n",
    "9000\t0.043000\t0.041755\t0.986873\t0.986873\t0.986903\t0.986873\n",
    "10000\t0.021900\t0.046021\t0.987245\t0.987245\t0.987250\t0.987245\n",
    "11000\t0.032800\t0.041483\t0.988454\t0.988453\t0.988471\t0.988454\n",
    "12000\t0.030500\t0.041880\t0.988305\t0.988305\t0.988312\t0.988305\n",
    "13000\t0.032300\t0.040375\t0.988565\t0.988565\t0.988567\t0.988565\n",
    "```"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model.save_pretrained(f\"./models/fake_news_bert_model_{language}\")\n",
    "tokenizer.save_pretrained(f\"./models/fake_news_bert_tokenizer_{language}\")"
   ]
  }
 ]
}
